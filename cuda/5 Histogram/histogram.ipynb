{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX1e2vRAI_zP",
        "outputId": "04d8bdbc-ae35-4521-cf49-788cfdc509e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n",
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpxepu_b6l\".\n"
          ]
        }
      ],
      "source": [
        "!python --version\n",
        "!nvcc --version\n",
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "struct GpuTimer {\n",
        "      cudaEvent_t start;\n",
        "      cudaEvent_t stop;\n",
        "\n",
        "      GpuTimer()\n",
        "      {\n",
        "            cudaEventCreate(&start);\n",
        "            cudaEventCreate(&stop);\n",
        "      }\n",
        "\n",
        "      ~GpuTimer()\n",
        "      {\n",
        "            cudaEventDestroy(start);\n",
        "            cudaEventDestroy(stop);\n",
        "      }\n",
        "\n",
        "      void Start()\n",
        "      {\n",
        "            cudaEventRecord(start, 0);\n",
        "      }\n",
        "\n",
        "      void Stop()\n",
        "      {\n",
        "            cudaEventRecord(stop, 0);\n",
        "      }\n",
        "\n",
        "      float Elapsed()\n",
        "      {\n",
        "            float elapsed;\n",
        "            cudaEventSynchronize(stop);\n",
        "            cudaEventElapsedTime(&elapsed, start, stop);\n",
        "            return elapsed;\n",
        "      }\n",
        "};\n",
        "\n",
        "\n",
        "int log2(int i)\n",
        "{\n",
        "    int r = 0;\n",
        "    while (i >>= 1) r++;\n",
        "    return r;\n",
        "}\n",
        "\n",
        "int bit_reverse(int w, int bits)\n",
        "{\n",
        "    int r = 0;\n",
        "    for (int i = 0; i < bits; i++)\n",
        "    {\n",
        "        int bit = (w & (1 << i)) >> i;\n",
        "        r |= bit << (bits - i - 1);\n",
        "    }\n",
        "    return r;\n",
        "}\n",
        "\n",
        "__global__ void naive_histo(int *d_bins, const int *d_in, const int BIN_COUNT)\n",
        "{\n",
        "    int myId = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "    int myItem = d_in[myId];\n",
        "    int myBin = myItem % BIN_COUNT;\n",
        "    d_bins[myBin]++;\n",
        "}\n",
        "\n",
        "__global__ void simple_histo(int *d_bins, const int *d_in, const int BIN_COUNT)\n",
        "{\n",
        "    int myId = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "    int myItem = d_in[myId];\n",
        "    int myBin = myItem % BIN_COUNT;\n",
        "    atomicAdd(&(d_bins[myBin]), 1);\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    int deviceCount;\n",
        "    cudaGetDeviceCount(&deviceCount);\n",
        "    if (deviceCount == 0) {\n",
        "        fprintf(stderr, \"error: no devices supporting CUDA.\\n\");\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "    int dev = 0;\n",
        "    cudaSetDevice(dev);\n",
        "\n",
        "    cudaDeviceProp devProps;\n",
        "    if (cudaGetDeviceProperties(&devProps, dev) == 0)\n",
        "    {\n",
        "        printf(\"Using device %d:\\n\", dev);\n",
        "        printf(\"%s; global mem: %dB; compute v%d.%d; clock: %d kHz\\n\",\n",
        "               devProps.name, (int)devProps.totalGlobalMem,\n",
        "               (int)devProps.major, (int)devProps.minor,\n",
        "               (int)devProps.clockRate);\n",
        "    }\n",
        "\n",
        "    const int ARRAY_SIZE = 65536;\n",
        "    const int ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
        "    const int BIN_COUNT = 16;\n",
        "    const int BIN_BYTES = BIN_COUNT * sizeof(int);\n",
        "\n",
        "    // generate the input array on the host\n",
        "    int h_in[ARRAY_SIZE];\n",
        "    for(int i = 0; i < ARRAY_SIZE; i++) {\n",
        "        h_in[i] = bit_reverse(i, log2(ARRAY_SIZE));\n",
        "    }\n",
        "    int h_bins[BIN_COUNT];\n",
        "    for(int i = 0; i < BIN_COUNT; i++) {\n",
        "        h_bins[i] = 0;\n",
        "    }\n",
        "\n",
        "    // declare GPU memory pointers\n",
        "    int * d_in;\n",
        "    int * d_bins;\n",
        "\n",
        "    // allocate GPU memory\n",
        "    cudaMalloc((void **) &d_in, ARRAY_BYTES);\n",
        "    cudaMalloc((void **) &d_bins, BIN_BYTES);\n",
        "\n",
        "    // transfer the arrays to the GPU\n",
        "    cudaMemcpy(d_in, h_in, ARRAY_BYTES, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_bins, h_bins, BIN_BYTES, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int whichKernel = 0;\n",
        "    if (argc == 2) {\n",
        "        whichKernel = atoi(argv[1]);\n",
        "    }\n",
        "\n",
        "    // launch the kernel\n",
        "    GpuTimer timer;\n",
        "    timer.Start();\n",
        "    switch(whichKernel) {\n",
        "    case 0:\n",
        "        printf(\"Running naive histo\\n\");\n",
        "        naive_histo<<<ARRAY_SIZE / 64, 64>>>(d_bins, d_in, BIN_COUNT);\n",
        "\n",
        "        break;\n",
        "    case 1:\n",
        "        printf(\"Running simple histo\\n\");\n",
        "        simple_histo<<<ARRAY_SIZE / 64, 64>>>(d_bins, d_in, BIN_COUNT);\n",
        "        break;\n",
        "    default:\n",
        "        fprintf(stderr, \"error: ran no kernel\\n\");\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "    timer.Stop();\n",
        "\n",
        "    // copy back the sum from GPU\n",
        "    cudaMemcpy(h_bins, d_bins, BIN_BYTES, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // for(int i = 0; i < BIN_COUNT; i++) {\n",
        "    //     printf(\"bin %d: count %d\\n\", i, h_bins[i]);\n",
        "    // }\n",
        "    printf(\"naive; array_size: %d; bin_count: %d,time: %f\",ARRAY_SIZE, BIN_COUNT, timer.Elapsed());\n",
        "    // free GPU memory allocation\n",
        "    cudaFree(d_in);\n",
        "    cudaFree(d_bins);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0oYbPidCtT1",
        "outputId": "322a2dfe-321e-483e-99fe-66c255e4bc92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device 0:\n",
            "Tesla T4; global mem: -1344208896B; compute v7.5; clock: 1590000 kHz\n",
            "Running naive histo\n",
            "naive; array_size: 1048576; bin_count: 64,time: 0.253120\n"
          ]
        }
      ]
    }
  ]
}