{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4IUGHqq749S",
        "outputId": "efa4f4e8-bfc4-42b9-e920-47708e116d63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.10.12\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n",
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpytz1zwwk\".\n"
          ]
        }
      ],
      "source": [
        "!python --version\n",
        "!nvcc --version\n",
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMIGU5rC8Z6a",
        "outputId": "94f7a9cf-ea7f-402f-bd7a-12f3b15b8179"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n;type;block_size;elapsed_time\n",
            "1048576;naive;8;;0.240448\n",
            "1048576;naive;16;;0.036640\n",
            "1048576;naive;32;;0.062944\n",
            "1048576;naive;64;;0.008672\n",
            "4194304;naive;8;;0.065856\n",
            "4194304;naive;16;;0.088256\n",
            "4194304;naive;32;;0.200672\n",
            "4194304;naive;64;;0.008832\n",
            "16777216;naive;8;;0.234144\n",
            "16777216;naive;16;;0.314784\n",
            "16777216;naive;32;;0.763456\n",
            "16777216;naive;64;;0.010176\n",
            "67108864;naive;8;;0.945408\n",
            "67108864;naive;16;;1.246368\n",
            "67108864;naive;32;;2.935136\n",
            "67108864;naive;64;;0.009344\n",
            "268435456;naive;8;;6.120992\n",
            "268435456;naive;16;;5.703744\n",
            "268435456;naive;32;;11.725920\n",
            "268435456;naive;64;;0.008288\n",
            "1073741824;naive;8;;24.947041\n",
            "1073741824;naive;16;;25.917408\n",
            "1073741824;naive;32;;46.681728\n",
            "1073741824;naive;64;;0.008576\n",
            "512;shared;8;0.044448\n",
            "512;shared;16;0.035104\n",
            "512;shared;32;0.043072\n",
            "512;shared;64;1.058688\n",
            "1024;shared;8;0.125120\n",
            "1024;shared;16;0.078784\n",
            "1024;shared;32;0.106304\n",
            "1024;shared;64;1.058944\n",
            "2048;shared;8;0.451008\n",
            "2048;shared;16;0.247808\n",
            "2048;shared;32;0.310848\n",
            "2048;shared;64;0.007776\n",
            "4096;shared;8;1.492320\n",
            "4096;shared;16;0.798336\n",
            "4096;shared;32;1.180384\n",
            "4096;shared;64;0.007936\n",
            "8192;shared;8;7.011552\n",
            "8192;shared;16;3.634144\n",
            "8192;shared;32;4.699072\n",
            "8192;shared;64;0.008544\n",
            "16384;shared;8;39.989761\n",
            "16384;shared;16;19.806976\n",
            "16384;shared;32;27.395041\n",
            "16384;shared;64;0.008768\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "#define SHARED_BLOCK_SIZE 64\n",
        "\n",
        "struct GpuTimer {\n",
        "      cudaEvent_t start;\n",
        "      cudaEvent_t stop;\n",
        "\n",
        "      GpuTimer()\n",
        "      {\n",
        "            cudaEventCreate(&start);\n",
        "            cudaEventCreate(&stop);\n",
        "      }\n",
        "\n",
        "      ~GpuTimer()\n",
        "      {\n",
        "            cudaEventDestroy(start);\n",
        "            cudaEventDestroy(stop);\n",
        "      }\n",
        "\n",
        "      void Start()\n",
        "      {\n",
        "            cudaEventRecord(start, 0);\n",
        "      }\n",
        "\n",
        "      void Stop()\n",
        "      {\n",
        "            cudaEventRecord(stop, 0);\n",
        "      }\n",
        "\n",
        "      float Elapsed()\n",
        "      {\n",
        "            float elapsed;\n",
        "            cudaEventSynchronize(stop);\n",
        "            cudaEventElapsedTime(&elapsed, start, stop);\n",
        "            return elapsed;\n",
        "      }\n",
        "};\n",
        "\n",
        "\n",
        "\n",
        "__global__ void matrix_transpose_naive(int *input, int *output, int n) {\n",
        "\n",
        "\tint indexX = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\tint indexY = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "\tint index = indexY * n + indexX;\n",
        "\tint transposedIndex = indexX * n + indexY;\n",
        "\n",
        "    // this has discoalesced global memory store\n",
        "\toutput[transposedIndex] = input[index];\n",
        "\n",
        "\t// this has discoalesced global memore load\n",
        "\t// output[index] = input[transposedIndex];\n",
        "}\n",
        "\n",
        "__global__ void matrix_transpose_shared(int *input, int *output, int n) {\n",
        "\n",
        "\t__shared__ int sharedMemory [SHARED_BLOCK_SIZE] [SHARED_BLOCK_SIZE];\n",
        "\n",
        "\t// global index\n",
        "\tint indexX = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\tint indexY = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "\n",
        "\t// transposed global memory index\n",
        "\tint tindexX = threadIdx.x + blockIdx.y * blockDim.x;\n",
        "\tint tindexY = threadIdx.y + blockIdx.x * blockDim.y;\n",
        "\n",
        "\t// local index\n",
        "\tint localIndexX = threadIdx.x;\n",
        "\tint localIndexY = threadIdx.y;\n",
        "\n",
        "\tint index = indexY * n + indexX;\n",
        "\tint transposedIndex = tindexY * n + tindexX;\n",
        "\n",
        "\t// reading from global memory in coalesed manner and performing tanspose in shared memory\n",
        "\tsharedMemory[localIndexX][localIndexY] = input[index];\n",
        "\n",
        "\t__syncthreads();\n",
        "\n",
        "\t// writing into global memory in coalesed fashion via transposed data in shared memory\n",
        "\toutput[transposedIndex] = sharedMemory[localIndexY][localIndexX];\n",
        "}\n",
        "\n",
        "void fill_array(int *data, int n) {\n",
        "\tfor(int idx=0;idx<(n*n);idx++)\n",
        "\t\tdata[idx] = idx;\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main(void) {\n",
        "  int sizes[] = {512, 1024, 2048, 4096, 8192, 16384};\n",
        "\tint blocks[] = {8, 16, 32, 64};\n",
        "\tint *a, *b;\n",
        "  int *d_a, *d_b;\n",
        "\n",
        "  printf(\"n;type;block_size;elapsed_time\\n\");\n",
        "\n",
        "\n",
        "  for(int s = 0; s < sizeof(sizes) / sizeof(sizes[0]); s++) {\n",
        "        int n = sizes[s];\n",
        "        int size = n * n * sizeof(int);\n",
        "\n",
        "        for (int t = 0; t < sizeof(blocks) / sizeof(blocks[0]); t++) {\n",
        "\n",
        "            a = (int *)malloc(size); fill_array(a, n);\n",
        "            b = (int *)malloc(size);\n",
        "\n",
        "\n",
        "            cudaMalloc((void **)&d_a, size);\n",
        "            cudaMalloc((void **)&d_b, size);\n",
        "\n",
        "            cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n",
        "            cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "            GpuTimer timer;\n",
        "\n",
        "            int block_size = blocks[t];\n",
        "\n",
        "            dim3 blockSize(block_size,block_size,1);\n",
        "            dim3 gridSize(n/block_size,n/block_size,1);\n",
        "\n",
        "            timer.Start();\n",
        "            matrix_transpose_naive<<<gridSize,blockSize>>>(d_a,d_b, n);\n",
        "            cudaDeviceSynchronize();\n",
        "            timer.Stop();\n",
        "            printf(\"%d;naive;%d;;%f\\n\",size,block_size,timer.Elapsed());\n",
        "\n",
        "            free(a); free(b);\n",
        "            cudaFree(d_a); cudaFree(d_b);\n",
        "        }\n",
        "\n",
        "    }\n",
        "\n",
        "\n",
        "  for(int s = 0; s < sizeof(sizes) / sizeof(sizes[0]); s++) {\n",
        "        int n = sizes[s];\n",
        "        int size = n * n * sizeof(int);\n",
        "\n",
        "        for (int t = 0; t < sizeof(blocks) / sizeof(blocks[0]); t++) {\n",
        "\n",
        "            a = (int *)malloc(size); fill_array(a, n);\n",
        "            b = (int *)malloc(size);\n",
        "\n",
        "\n",
        "            cudaMalloc((void **)&d_a, size);\n",
        "            cudaMalloc((void **)&d_b, size);\n",
        "\n",
        "            cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n",
        "            cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "            GpuTimer timer;\n",
        "\n",
        "            int block_size = blocks[t];\n",
        "\n",
        "            dim3 blockSize(block_size,block_size,1);\n",
        "            dim3 gridSize(n/block_size,n/block_size,1);\n",
        "\n",
        "            timer.Start();\n",
        "            matrix_transpose_shared<<<gridSize,blockSize>>>(d_a,d_b, n);\n",
        "            cudaDeviceSynchronize();\n",
        "            timer.Stop();\n",
        "            printf(\"%d;shared;%d;%f\\n\",n,block_size,timer.Elapsed());\n",
        "\n",
        "            free(a); free(b);\n",
        "            cudaFree(d_a); cudaFree(d_b);\n",
        "        }\n",
        "\n",
        "    }\n",
        "\n",
        "\n",
        "\treturn 0;\n",
        "}\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
